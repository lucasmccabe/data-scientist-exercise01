{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas McCabe\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11687 individuals earning >$50k (23.93%)\n",
      "37155 individuals earning <=$50k (76.07%)\n",
      "\n",
      "Summary of continuous variables:\n",
      "\n",
      "                age  education_num  capital_gain  capital_loss    hours_week\n",
      "count  48842.000000   48842.000000  48842.000000  48842.000000  48842.000000\n",
      "mean      38.643585      10.078089   1079.067626     87.502314     40.422382\n",
      "std       13.710510       2.570973   7452.019058    403.004552     12.391444\n",
      "min       17.000000       1.000000      0.000000      0.000000      1.000000\n",
      "25%       28.000000       9.000000      0.000000      0.000000     40.000000\n",
      "50%       37.000000      10.000000      0.000000      0.000000     40.000000\n",
      "75%       48.000000      12.000000      0.000000      0.000000     45.000000\n",
      "max       90.000000      16.000000  99999.000000   4356.000000     99.000000\n"
     ]
    }
   ],
   "source": [
    "#initial data exploration\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "\n",
    "records = pd.DataFrame.from_csv('records.csv')\n",
    "over_50 = records.loc[records['over_50k'] == 1] #all rows where income > $50k\n",
    "under_50 = records.loc[records['over_50k'] == 0] #all rows where income <= $50k\n",
    "\n",
    "#some general information about the dataset\n",
    "print(str(over_50.shape[0]) + ' individuals earning >$50k (' + str('%.2f'%(100*over_50.shape[0]/(over_50.shape[0]+under_50.shape[0]))) + '%)')\n",
    "print(str(under_50.shape[0]) + ' individuals earning <=$50k (' + str('%.2f'%(100*under_50.shape[0]/(over_50.shape[0]+under_50.shape[0]))) + '%)')\n",
    "print('\\nSummary of continuous variables:\\n')\n",
    "print(records.drop(['over_50k'], axis=1).describe()) #summary statistics for each continuous variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly 24% of the data set is made up of individuals earning greater than \\$50,000, and roughly 76% of the data is made up of individuals earning less than or equal to \\$50,000. The means, standard deviations, and quartiles of the capital gain and capital loss variables indicate to me that the variables are heavily skewed, but I will verify this below. At least half the individuals in the dataset work for 40-45 hours per week, so I doubt over_50k will be strongly correlated to hours worked alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of continuous variables:\n",
      "\n",
      "age               0.557580\n",
      "education_num    -0.316525\n",
      "capital_gain     11.894659\n",
      "capital_loss      4.569809\n",
      "hours_week        0.238750\n",
      "over_50k          1.222216\n",
      "dtype: float64\n",
      "\n",
      "Number of instances of both non-zero capital gain and capital loss: 0\n"
     ]
    }
   ],
   "source": [
    "#obervations re: capital gain/loss\n",
    "print('Skewness of continuous variables:\\n')\n",
    "print(records.skew())\n",
    "\n",
    "print('\\nNumber of instances of both non-zero capital gain and capital loss: ' + str(records.loc[(records['capital_gain'] >0) & (records['capital_loss'] >0)].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capital gain and capital loss are heavily skewed variables, whereas the other continuous variables are not particularly skewed. They are also mutually-exclusive in that there are zero instances of both non-zero capital gain and capital loss. For this reason, I think it would be a good idea to consolidate the two variables into one variable representing the net capital gain/loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skewness of continuous variables:\n",
      "\n",
      "age               0.557580\n",
      "education_num    -0.316525\n",
      "hours_week        0.238750\n",
      "delta_capital    11.814939\n",
      "over_50k          1.222216\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "records['delta_capital'] = records['capital_gain'] - records['capital_loss'] #create net capital gain/loss variable\n",
    "records.drop('capital_gain', axis=1, inplace=True) #we don't need this anymore\n",
    "records.drop('capital_loss', axis=1, inplace=True) #we don't need this anymore\n",
    "\n",
    "#now over_50k is no longer the rightmost column, so I'm going to swap it with the delta_capital column\n",
    "cols = list(records)\n",
    "cols[11], cols[12] = cols[12], cols[11]\n",
    "records = records.loc[:, cols]\n",
    "\n",
    "print('\\nSkewness of continuous variables:\\n')\n",
    "print(records.skew())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictably, the delta_capital variable is heavily skewed, just like its parent variables. I would like to use a logarithmic transformation so that particularly high or low values don't interfere with training the model. I will also normalize the continuous variables by their z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                age  education_num    hours_week  delta_capital      over_50k\n",
      "count  4.884200e+04   4.884200e+04  4.884200e+04   4.656000e+04  48842.000000\n",
      "mean   4.303075e-16  -7.796702e-17 -3.416410e-16  -5.233071e-16      0.239282\n",
      "std    1.000000e+00   1.000000e+00  1.000000e+00   1.000000e+00      0.426649\n",
      "min   -1.578613e+00  -3.530994e+00 -3.181420e+00  -3.057938e-01      0.000000\n",
      "25%   -7.763085e-01  -4.193310e-01 -3.408661e-02  -3.057938e-01      0.000000\n",
      "50%   -1.198778e-01  -3.037315e-02 -3.408661e-02  -3.057938e-01      0.000000\n",
      "75%    6.824264e-01   7.475425e-01  3.694176e-01  -3.057938e-01      0.000000\n",
      "max    3.745770e+00   2.303374e+00  4.727263e+00   4.300778e+00      1.000000\n"
     ]
    }
   ],
   "source": [
    "records['delta_capital'] = records['delta_capital'].apply(lambda i: np.log(i+1)) #log normalization\n",
    "cont_cols = ['age','education_num','hours_week','delta_capital'] #list of continuous variables\n",
    "records[cont_cols] = (records[cont_cols] - records[cont_cols].mean())/records[cont_cols].std() #z-score normalize continuous variables\n",
    "print(records.describe())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that the data is normalized, I would like to take a look at the instances of '?' in the data set, representing missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances of ? in age: 0\n",
      "Instances of ? in workclass_id: 2799\n",
      "Instances of ? in education_level_id: 0\n",
      "Instances of ? in education_num: 0\n",
      "Instances of ? in marital_status_id: 0\n",
      "Instances of ? in occupation_id: 2809\n",
      "Instances of ? in relationship_id: 0\n",
      "Instances of ? in race_id: 0\n",
      "Instances of ? in sex_id: 0\n",
      "Instances of ? in hours_week: 0\n",
      "Instances of ? in country_id: 857\n",
      "Instances of ? in delta_capital: 0\n",
      "Instances of ? in over_50k: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas McCabe\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:816: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = getattr(x, name)(y)\n"
     ]
    }
   ],
   "source": [
    "col_names = records.columns.tolist() #gets all column names, converts index to list\n",
    "for i in col_names:\n",
    "    try:\n",
    "        count = records.loc[records[i] == '?'].shape[0] #number of rows that have ? in column i\n",
    "        print('Instances of ? in ' + i + ': '+ str(count))\n",
    "    except: #general error handling\n",
    "        print('Instances of ? in ' + i + ': 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suspect that the vast majority of instances of ? in workclas_id and occupation_id occur in the same rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances of both ? in both workclass_id and occupation_id: 2799\n",
      "Instances of both ? in both workclass_id and country_id: 46\n",
      "Instances of both ? in both country_id and occupation_id: 46\n",
      "Instances of ? in workclass_id, country_id, and occupation_id: 46\n",
      "Total instances of ?: 3620 (7.41%)\n"
     ]
    }
   ],
   "source": [
    "count_wo = records.loc[(records['workclass_id'] == '?') & (records['occupation_id'] == '?')].shape[0] #instances of ? in both workclass_id and occupation_id\n",
    "count_wc = records.loc[(records['workclass_id'] == '?') & (records['country_id'] == '?')].shape[0] #instances of ? in both workclass_id and country_id\n",
    "count_co = records.loc[(records['country_id'] == '?') & (records['occupation_id'] == '?')].shape[0] #instances of ? in both country_id and occupation_id\n",
    "count_wco = records.loc[(records['workclass_id'] == '?') & (records['country_id'] == '?') & (records['occupation_id'] == '?')].shape[0] #instances of ? in workclass_id, country_id, and occupation_id\n",
    "count_q = records.loc[(records['workclass_id'] == '?') | (records['country_id'] == '?') | (records['occupation_id'] == '?')].shape[0] #instances of ? in any of workclass_id, country_id, and occupation_id\n",
    "\n",
    "print('Instances of both ? in both workclass_id and occupation_id: ' + str(count_wo))\n",
    "print('Instances of both ? in both workclass_id and country_id: ' + str(count_wc))\n",
    "print('Instances of both ? in both country_id and occupation_id: ' + str(count_co))\n",
    "print('Instances of ? in workclass_id, country_id, and occupation_id: ' + str(count_wco))\n",
    "print('Total instances of ?: ' + str(count_q) + ' (' + str('%.2f'%(100*count_q/(records.shape[0]))) + '%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every instance of ? in workclass_id coincides with an instance of ? in occupation_id. There are a few rare instances of ? occuring in workclass_id, country_id, and occupation_id. Since only 7.41% of the rows have missing data, I think it would be safe to just remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances of ?: 0 (0.00%)\n",
      "\n",
      "                age  education_num    hours_week  delta_capital      over_50k\n",
      "count  45222.000000   45222.000000  45222.000000   43082.000000  45222.000000\n",
      "mean      -0.006976       0.015703      0.041612       0.005323      0.247844\n",
      "std        0.964068       0.992963      0.969016       1.008858      0.431766\n",
      "min       -1.578613      -3.530994     -3.181420      -0.305794      0.000000\n",
      "25%       -0.776309      -0.419331     -0.034087      -0.305794      0.000000\n",
      "50%       -0.119878      -0.030373     -0.034087      -0.305794      0.000000\n",
      "75%        0.609490       1.136500      0.369418      -0.305794      0.000000\n",
      "max        3.745770       2.303374      4.727263       4.300778      1.000000\n"
     ]
    }
   ],
   "source": [
    "records = records.loc[(records['workclass_id'] != '?') & (records['country_id'] != '?') & (records['occupation_id'] != '?')]\n",
    "count_q = records.loc[(records['workclass_id'] == '?') | (records['country_id'] == '?') | (records['occupation_id'] == '?')].shape[0]\n",
    "print('Total instances of ?: ' + str(count_q) + ' (' + str('%.2f'%(100*count_q/(records.shape[0]))) + '%)\\n')\n",
    "print(records.describe())\n",
    "records.to_csv('normalized_records.csv', sep=',') #save normalized records as csv for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because several of the variables are categorical, I would like to one-hot encode the categorical data so that the model can use it more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.get_dummies(records)\n",
    "records.to_csv('processed_data.csv', sep=',') #save final processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is consolidated, normalized, encoded, and saved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
